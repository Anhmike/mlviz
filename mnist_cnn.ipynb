{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "mnist = read_data_sets('data', one_hot=True, reshape=False, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(Y, is_test, i, offset, is_conv=False):\n",
    "    ema = tf.train.ExponentialMovingAverage(0.999, i)\n",
    "    if is_conv:\n",
    "        # for conv layers compute moments across 3 dims (W, H, D)\n",
    "        mean, variance = tf.nn.moments(Y, [0, 1, 2])\n",
    "    else: \n",
    "        # for FC layers compute moments across just 1 dim\n",
    "        mean, variance = tf.nn.moments(Y, [0])\n",
    "    update_ma = ema.apply([mean, variance])\n",
    "    \n",
    "    # for test run use EMA and for train use the mean\n",
    "    m = tf.cond(is_test, lambda: ema.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: ema.average(variance), lambda: variance)\n",
    "    \n",
    "    # note that scale is not needed for relu!\n",
    "    Ybn = tf.nn.batch_normalization(Y, m, v, offset, None, variance_epsilon=1e-5)\n",
    "    return Ybn, update_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# place holders for inputs/outputs\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# learning rate\n",
    "lr = tf.placeholder(tf.float32)\n",
    "# batch norm during test?\n",
    "bn_test = tf.placeholder(tf.bool)\n",
    "# iteration counter\n",
    "it = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convolutional layer 1 hyperparms\n",
    "F = 5 # filter size\n",
    "S = 1 # stride\n",
    "K = 4 # num filters\n",
    "\n",
    "# fully connected layer\n",
    "N = 200\n",
    "\n",
    "# FxF filter, 1 input channel, K output channels\n",
    "W1 = tf.Variable(tf.truncated_normal([F, F, 1, K], stddev=0.1))  \n",
    "B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\n",
    "\n",
    "# fully connected layer, 28 * 28 * K inputs, N outputs (since 'SAME' padding will be used)\n",
    "W2 = tf.Variable(tf.truncated_normal([28 * 28 * K, N], stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\n",
    "\n",
    "# final layer of 10 nodes for 10 classes\n",
    "W3 = tf.Variable(tf.truncated_normal([N, 10], stddev=0.1))\n",
    "B3 = tf.Variable(tf.constant(0.1, tf.float32, [10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "\n",
    "# conv layer\n",
    "# no need for bias since batch norm is being performed!\n",
    "Y1_conv = tf.nn.conv2d(X, W1, strides=[1, S, S, 1], padding='SAME')\n",
    "# use bias as offset for batch norm\n",
    "Y1bn, ema1 = batchnorm(Y1_conv, bn_test, it, B1, is_conv=True)\n",
    "Y1 = tf.nn.relu(Y1bn)\n",
    "\n",
    "# reshape the output from the conv layer for the FC layer\n",
    "Y1_reshaped = tf.reshape(Y1, shape=[-1, 28 * 28 * K])\n",
    "# no need for bias since batch norm is being performed!\n",
    "Y2_fc = tf.matmul(Y1_reshaped, W2)\n",
    "# use bias as offset for batch norm\n",
    "Y2bn, ema2 = batchnorm(Y2_fc, bn_test, it, B2, is_conv=False)\n",
    "Y2 = tf.nn.relu(Y2bn)\n",
    "\n",
    "Y_logits = tf.matmul(Y2, W3) + B3\n",
    "Y_pred = tf.nn.softmax(Y_logits)\n",
    "\n",
    "# accumulate the moving averages\n",
    "ema = tf.group(ema1, ema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_logits, labels=Y_true)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy) * 100\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# training step\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# start an interactive session\n",
    "init = tf.global_variables_initializer()\n",
    "ses = tf.InteractiveSession()\n",
    "ses.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a72297d0c554ccf8f1df0e08e0ed265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import *\n",
    "import bqplot.pyplot as plt\n",
    "\n",
    "n = 200\n",
    "acc_fig = plt.figure(title='Accuracy', legend_location='bottom-right')\n",
    "x = np.arange(1, n+1)\n",
    "axes_options = {'x': {'label': 'Iterations', 'num_ticks': 5},\n",
    "                'y': {'tick_format': '.1%'}}\n",
    "acc_plot = plt.plot(x, [], display_legend=True, \n",
    "                    labels=['Train', 'Test'], colors=['green', 'blue'],\n",
    "                    axes_options=axes_options)\n",
    "\n",
    "loss_fig = plt.figure(title='Loss')\n",
    "loss_plot = plt.plot(np.arange(1, n+1), [], display_legend=True, \n",
    "                     labels=['Train', 'Test'], \n",
    "                     colors=['green', 'blue'],\n",
    "                     axes_options={'x': {'label': 'Iterations', \n",
    "                                         'num_ticks': 5},\n",
    "                                   'y': {'tick_format': ','}})\n",
    "HBox([acc_fig, loss_fig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "train_a = []\n",
    "test_a = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for i in range(200):\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "    \n",
    "    # learning rate decay\n",
    "    max_learning_rate = 0.02\n",
    "    min_learning_rate = 0.0001\n",
    "    decay_speed = 1600\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * np.exp(-i / decay_speed)\n",
    "\n",
    "    # train\n",
    "    ses.run(train_step, {X: batch_X,\n",
    "                         Y_true: batch_Y, \n",
    "                         lr: learning_rate, \n",
    "                         bn_test: False})\n",
    "    ses.run(ema, {X: batch_X, \n",
    "                  Y_true: batch_Y, \n",
    "                  bn_test: False, \n",
    "                  it: i})\n",
    "    a, c = ses.run([accuracy, cross_entropy], \n",
    "                   feed_dict={X: batch_X, \n",
    "                              Y_true: batch_Y,\n",
    "                              bn_test: False})\n",
    "    train_a.append(a)\n",
    "    train_loss.append(c * 100)\n",
    "    \n",
    "    # run on test data\n",
    "    test_data = {X: mnist.test.images, \n",
    "                 Y_true: mnist.test.labels,\n",
    "                 bn_test: True}\n",
    "    a, c = ses.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "    test_a.append(a)\n",
    "    test_loss.append(c)\n",
    "    \n",
    "    sleep(.001)\n",
    "    acc_plot.y = [train_a, test_a]\n",
    "    loss_plot.y = [train_loss, test_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# true test labels\n",
    "y_true = np.argmax(mnist.test.labels, 1)\n",
    "test_data = {X: mnist.test.images, Y_true: mnist.test.labels, bn_test: True}\n",
    "\n",
    "# pred test labels\n",
    "y_pred = np.argmax(ses.run(Y_pred, feed_dict=test_data), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bqplot import *\n",
    "\n",
    "class SquareMatrix(Figure):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.conf_mat = kwargs['matrix']\n",
    "        self.title = kwargs.get('title', '')\n",
    "        n = len(self.conf_mat)\n",
    "        self.labels = kwargs.get('labels', np.arange(n))\n",
    "        row_scale = OrdinalScale(reverse=True)\n",
    "        col_scale = OrdinalScale()\n",
    "        color_scale = ColorScale(scheme='Greens')\n",
    "        row_axis = Axis(scale=row_scale, orientation='vertical', label='Actual Label')\n",
    "        col_axis = Axis(scale=col_scale, label='Predicted Label')\n",
    "        self.conf_mat_grid = GridHeatMap(\n",
    "            column=self.labels,\n",
    "            row=self.labels,\n",
    "            color=(self.conf_mat ** .3),\n",
    "            scales={'row': row_scale, 'column': col_scale, 'color': color_scale},\n",
    "            interactions={'click': 'select'},\n",
    "            anchor_style={'stroke': 'red', 'stroke-width': 3},\n",
    "            selected_style={'stroke': 'red'})\n",
    "\n",
    "        y, x, text = zip(*[(self.labels[i],\n",
    "                            self.labels[j],\n",
    "                            str(self.conf_mat[i, j])) for i in range(n) for j in range(n)])\n",
    "\n",
    "        self.grid_labels = Label(x=x, y=y, text=text,\n",
    "                                 scales={'x': col_scale, \n",
    "                                         'y': row_scale},\n",
    "                                 font_size=16,\n",
    "                                 align='middle',\n",
    "                                 colors=['black'])\n",
    "\n",
    "        self.title = 'Confusion Matrix'\n",
    "        self.marks = [self.conf_mat_grid, self.grid_labels]\n",
    "        self.padding_y = 0.0\n",
    "        self.axes = [row_axis, col_axis]\n",
    "        self.fig_margin = dict(left=50, top=40, bottom=40, right=20)\n",
    "        self.layout.width = '460px'\n",
    "        self.layout.height = '400px'\n",
    "        \n",
    "        super(SquareMatrix, self).__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938b9668534741e7a4b86f4636fdb323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = SquareMatrix(matrix=conf_mat)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true, pred = cm.conf_mat_grid.selected[0]\n",
    "true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  72  149  244  318  629 1016 1050 1374 1459 1462 1609 1682 2186 2496 2517\n",
      " 2780 2959 3375 3681 3811 4100 4350 4997 5167 6528 7619 7627 8584 9613 9768\n",
      " 9811]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b21bc18>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBQhB8I6v8A56Wwsv4yIBsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b13f160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt1\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.squeeze(mnist.test.images)\n",
    "\n",
    "idx = np.argwhere((y_true == true) & (y_pred == pred)).squeeze()\n",
    "print(idx)\n",
    "plt1.imshow(X[idx[15]], cmap='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
