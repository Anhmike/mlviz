{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mnist = read_data_sets('data', one_hot=True, reshape=False, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "nH1 = 200\n",
    "nH2 = 100\n",
    "nH3 = 60\n",
    "nH4 = 30\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([784, nH1] ,stddev=0.1))\n",
    "B1 = tf.Variable(tf.ones([nH1]) / 10)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([nH1, nH2], stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([nH2]) / 10)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([nH2, nH3], stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([nH3]) / 10)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([nH3, nH4], stddev=0.1))\n",
    "B4 = tf.Variable(tf.ones([nH4]) / 10)\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([nH4, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.ones([10]) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "X1 = tf.reshape(X, [-1, 784])\n",
    "\n",
    "Y1 = tf.nn.relu(tf.matmul(X1, W1) + B1)\n",
    "Y1d = tf.nn.dropout(Y1, pkeep)\n",
    "\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1d, W2) + B2)\n",
    "Y2d = tf.nn.dropout(Y2, pkeep)\n",
    "\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2d, W3) + B3)\n",
    "Y3d = tf.nn.dropout(Y3, pkeep)\n",
    "\n",
    "Y4 = tf.nn.relu(tf.matmul(Y3d, W4) + B4)\n",
    "Y4d = tf.nn.dropout(Y4, pkeep)\n",
    "\n",
    "Y_logits = tf.matmul(Y4d, W5) + B5\n",
    "Y_pred = tf.nn.softmax(Y_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_logits, \n",
    "                                                        labels=Y_true)\n",
    "cross_entropy = tf.reduce_sum(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr = tf.placeholder(tf.float32)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "import bqplot.pyplot as plt\n",
    "\n",
    "n = 2000\n",
    "acc_fig = plt.figure(title='Accuracy')\n",
    "x = np.arange(1, n+1)\n",
    "axes_options = {'x': {'label': 'Iterations', 'num_ticks': 5},\n",
    "                'y': {'tick_format': '.0%'}}\n",
    "acc_plot = plt.plot(x, [], display_legend=True, \n",
    "                    labels=['Train', 'Test'], colors=['green', 'blue'],\n",
    "                    axes_options=axes_options)\n",
    "\n",
    "loss_fig = plt.figure(title='Loss')\n",
    "loss_plot = plt.plot(np.arange(1, n+1), [], display_legend=True, \n",
    "                     labels=['Train', 'Test'], \n",
    "                     colors=['green', 'blue'],\n",
    "                     axes_options={'x': {'label': 'Iterations', \n",
    "                                         'num_ticks': 5},\n",
    "                                   'y': {'tick_format': ','}})\n",
    "HBox([acc_fig, loss_fig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "train_a = []\n",
    "test_a = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "max_learning_rate = 0.003\n",
    "min_learning_rate = 0.0001\n",
    "decay_speed = 200.0\n",
    "\n",
    "# 10 epochs\n",
    "for i in range(1000):\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * np.exp(-i / decay_speed)\n",
    "    \n",
    "    # load batch of images and true values\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100) \n",
    "    train_data = {X: batch_X, Y_true: batch_Y, \n",
    "                  lr: learning_rate,\n",
    "                  pkeep: .75}\n",
    "    \n",
    "    # train\n",
    "    sess.run(train_step, feed_dict=train_data)\n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict=train_data)\n",
    "    train_a.append(a)\n",
    "    train_loss.append(c * 100)\n",
    "    \n",
    "    # run on test data (no dropout on test, pkeep = 1)\n",
    "    test_data = {X: mnist.test.images, Y_true: mnist.test.labels,\n",
    "                 pkeep: 1.}\n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "    test_a.append(a)\n",
    "    test_loss.append(c)\n",
    "    \n",
    "    sleep(.001)\n",
    "    if i % 10 == 0:\n",
    "        acc_plot.y = [train_a, test_a]\n",
    "        loss_plot.y = [train_loss, test_loss]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
